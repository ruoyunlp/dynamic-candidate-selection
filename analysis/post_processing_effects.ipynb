{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277a5c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from Levenshtein import distance\n",
    "from utils import *\n",
    "\n",
    "\n",
    "ROOT_DIR = '.'\n",
    "DATA_DIR = '.'\n",
    "\n",
    "tasks = ['atis', 'snips', 'clinic150', 'massive']\n",
    "cleaners = ['raw', 'lmclean2']\n",
    "models = {\n",
    "    'llama-3.1-8b-instruct': [\n",
    "        '4_bit_quant',\n",
    "        '4_bit_quant_k5',\n",
    "        '4_bit_quant_k10',\n",
    "        '8_bit_quant',\n",
    "        '8_bit_quant_k5',\n",
    "        '8_bit_quant_k10',\n",
    "        'full'\n",
    "    ],\n",
    "\n",
    "    'gemma-2-9b-it': [\n",
    "        '4_bit_quant',\n",
    "        '4_bit_quant_k5',\n",
    "        '4_bit_quant_k10',\n",
    "        '8_bit_quant',\n",
    "        '8_bit_quant_k5',\n",
    "        '8_bit_quant_k10',\n",
    "        'full'\n",
    "    ],\n",
    "\n",
    "    'phi-3-medium-4k-instruct': [\n",
    "        '4_bit_quant',\n",
    "        '4_bit_quant_k5',\n",
    "        '4_bit_quant_k10',\n",
    "        '8_bit_quant',\n",
    "        '8_bit_quant_k5',\n",
    "        '8_bit_quant_k10',\n",
    "        '16_bit_quant'\n",
    "    ],\n",
    "\n",
    "    'mistral-7b-instruct': [\n",
    "        '4_bit_quant',\n",
    "        '4_bit_quant_k5',\n",
    "        '4_bit_quant_k10',\n",
    "        '8_bit_quant',\n",
    "        '8_bit_quant_k5',\n",
    "        '8_bit_quant_k10',\n",
    "        'full'\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91ca1b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_to_intent(text, intents):\n",
    "    distances = torch.tensor([distance(text, intent) for intent in intents])\n",
    "    closest_match = intents[distances.argmin(dim=0)]\n",
    "    return closest_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd3490f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " acc: 0.7465 macro-f1: 0.5169\n",
      "74.65 51.69\n",
      " acc: 0.8163 macro-f1: 0.8190\n",
      "81.63 81.9\n",
      " acc: 0.8704 macro-f1: 0.8651\n",
      "87.04 86.51\n",
      " acc: 0.7290 macro-f1: 0.7235\n",
      "72.9 72.35\n",
      " acc: 0.7488 macro-f1: 0.5371\n",
      "74.88 53.71\n",
      " acc: 0.8167 macro-f1: 0.8194\n",
      "81.67 81.94\n",
      " acc: 0.8723 macro-f1: 0.8669\n",
      "87.23 86.69\n",
      " acc: 0.7323 macro-f1: 0.7270\n",
      "73.23 72.7\n",
      " acc: 0.7342 macro-f1: 0.5089\n",
      "73.42 50.89\n",
      " acc: 0.8102 macro-f1: 0.8207\n",
      "81.02 82.07\n",
      " acc: 0.8765 macro-f1: 0.8719\n",
      "87.65 87.19\n",
      " acc: 0.7437 macro-f1: 0.7385\n",
      "74.37 73.85\n",
      " acc: 0.7347 macro-f1: 0.5111\n",
      "73.47 51.11\n",
      " acc: 0.8104 macro-f1: 0.8210\n",
      "81.04 82.1\n",
      " acc: 0.8792 macro-f1: 0.8746\n",
      "87.92 87.46\n",
      " acc: 0.7450 macro-f1: 0.7392\n",
      "74.5 73.92\n",
      " acc: 0.7458 macro-f1: 0.4751\n",
      "74.58 47.51\n",
      " acc: 0.7633 macro-f1: 0.7756\n",
      "76.33 77.56\n",
      " acc: 0.8846 macro-f1: 0.8810\n",
      "88.46 88.1\n",
      " acc: 0.7456 macro-f1: 0.7403\n",
      "74.56 74.03\n",
      " acc: 0.7476 macro-f1: 0.4805\n",
      "74.76 48.05\n",
      " acc: 0.7633 macro-f1: 0.7758\n",
      "76.33 77.58\n",
      " acc: 0.8872 macro-f1: 0.8835\n",
      "88.72 88.35\n",
      " acc: 0.7466 macro-f1: 0.7413\n",
      "74.66 74.13\n",
      " acc: 0.7580 macro-f1: 0.5040\n",
      "75.8 50.4\n",
      " acc: 0.7918 macro-f1: 0.7854\n",
      "79.18 78.54\n",
      " acc: 0.8777 macro-f1: 0.8721\n",
      "87.77 87.21\n",
      " acc: 0.7279 macro-f1: 0.7205\n",
      "72.79 72.05\n",
      " acc: 0.7640 macro-f1: 0.5309\n",
      "76.4 53.09\n",
      " acc: 0.7924 macro-f1: 0.7861\n",
      "79.24 78.61\n",
      " acc: 0.8787 macro-f1: 0.8731\n",
      "87.87 87.31\n",
      " acc: 0.7311 macro-f1: 0.7239\n",
      "73.11 72.39\n",
      " acc: 0.7297 macro-f1: 0.4488\n",
      "72.97 44.88\n",
      " acc: 0.7571 macro-f1: 0.7563\n",
      "75.71 75.63\n",
      " acc: 0.8842 macro-f1: 0.8802\n",
      "88.42 88.02\n",
      " acc: 0.7428 macro-f1: 0.7312\n",
      "74.28 73.12\n",
      " acc: 0.7436 macro-f1: 0.4977\n",
      "74.36 49.77\n",
      " acc: 0.7572 macro-f1: 0.7565\n",
      "75.72 75.65\n",
      " acc: 0.8848 macro-f1: 0.8808\n",
      "88.48 88.08\n",
      " acc: 0.7443 macro-f1: 0.7329\n",
      "74.43 73.29\n",
      " acc: 0.7064 macro-f1: 0.4078\n",
      "70.64 40.78\n",
      " acc: 0.7236 macro-f1: 0.7224\n",
      "72.36 72.24\n",
      " acc: 0.8867 macro-f1: 0.8825\n",
      "88.67 88.25\n",
      " acc: 0.7490 macro-f1: 0.7393\n",
      "74.9 73.93\n",
      " acc: 0.7448 macro-f1: 0.4651\n",
      "74.48 46.51\n",
      " acc: 0.7238 macro-f1: 0.7226\n",
      "72.38 72.26\n",
      " acc: 0.8880 macro-f1: 0.8839\n",
      "88.8 88.39\n",
      " acc: 0.7498 macro-f1: 0.7403\n",
      "74.98 74.03\n",
      " acc: 0.7831 macro-f1: 0.5165\n",
      "78.31 51.65\n",
      " acc: 0.7985 macro-f1: 0.7928\n",
      "79.85 79.28\n",
      " acc: 0.8791 macro-f1: 0.8738\n",
      "87.91 87.38\n",
      " acc: 0.7275 macro-f1: 0.7188\n",
      "72.75 71.88\n",
      " acc: 0.7858 macro-f1: 0.5318\n",
      "78.58 53.18\n",
      " acc: 0.7989 macro-f1: 0.7934\n",
      "79.89 79.34\n",
      " acc: 0.8800 macro-f1: 0.8747\n",
      "88 87.47\n",
      " acc: 0.7308 macro-f1: 0.7224\n",
      "73.08 72.24\n",
      " acc: 0.8629 macro-f1: 0.5438\n",
      "86.29 54.38\n",
      " acc: 0.9288 macro-f1: 0.9305\n",
      "92.88 93.05\n",
      " acc: 0.8951 macro-f1: 0.8907\n",
      "89.51 89.07\n",
      " acc: 0.7458 macro-f1: 0.7381\n",
      "74.58 73.81\n",
      " acc: 0.8643 macro-f1: 0.5219\n",
      "86.43 52.19\n",
      " acc: 0.9310 macro-f1: 0.9325\n",
      "93.1 93.25\n",
      " acc: 0.8962 macro-f1: 0.8919\n",
      "89.62 89.19\n",
      " acc: 0.7487 macro-f1: 0.7419\n",
      "74.87 74.19\n",
      " acc: 0.8529 macro-f1: 0.5323\n",
      "85.29 53.23\n",
      " acc: 0.9075 macro-f1: 0.9120\n",
      "90.75 91.2\n",
      " acc: 0.9025 macro-f1: 0.8990\n",
      "90.25 89.9\n",
      " acc: 0.7655 macro-f1: 0.7484\n",
      "76.55 74.84\n",
      " acc: 0.8555 macro-f1: 0.5167\n",
      "85.55 51.67\n",
      " acc: 0.9131 macro-f1: 0.9169\n",
      "91.31 91.69\n",
      " acc: 0.9032 macro-f1: 0.8996\n",
      "90.32 89.96\n",
      " acc: 0.7670 macro-f1: 0.7506\n",
      "76.7 75.06\n",
      " acc: 0.8524 macro-f1: 0.5130\n",
      "85.24 51.3\n",
      " acc: 0.9047 macro-f1: 0.9100\n",
      "90.47 91\n",
      " acc: 0.9014 macro-f1: 0.8976\n",
      "90.14 89.76\n",
      " acc: 0.7647 macro-f1: 0.7483\n",
      "76.47 74.83\n",
      " acc: 0.8553 macro-f1: 0.4969\n",
      "85.53 49.69\n",
      " acc: 0.9169 macro-f1: 0.9206\n",
      "91.69 92.06\n",
      " acc: 0.9026 macro-f1: 0.8987\n",
      "90.26 89.87\n",
      " acc: 0.7659 macro-f1: 0.7508\n",
      "76.59 75.08\n",
      " acc: 0.8641 macro-f1: 0.5620\n",
      "86.41 56.2\n",
      " acc: 0.9370 macro-f1: 0.9382\n",
      "93.7 93.82\n",
      " acc: 0.8990 macro-f1: 0.8947\n",
      "89.9 89.47\n",
      " acc: 0.7487 macro-f1: 0.7426\n",
      "74.87 74.26\n",
      " acc: 0.8653 macro-f1: 0.5402\n",
      "86.53 54.02\n",
      " acc: 0.9381 macro-f1: 0.9392\n",
      "93.81 93.92\n",
      " acc: 0.8994 macro-f1: 0.8957\n",
      "89.94 89.57\n",
      " acc: 0.7504 macro-f1: 0.7473\n",
      "75.04 74.73\n",
      " acc: 0.8555 macro-f1: 0.5594\n",
      "85.55 55.94\n",
      " acc: 0.9259 macro-f1: 0.9290\n",
      "92.59 92.9\n",
      " acc: 0.9074 macro-f1: 0.9039\n",
      "90.74 90.39\n",
      " acc: 0.7696 macro-f1: 0.7572\n",
      "76.96 75.72\n",
      " acc: 0.8572 macro-f1: 0.5373\n",
      "85.72 53.73\n",
      " acc: 0.9274 macro-f1: 0.9304\n",
      "92.74 93.04\n",
      " acc: 0.9079 macro-f1: 0.9046\n",
      "90.79 90.46\n",
      " acc: 0.7709 macro-f1: 0.7597\n",
      "77.09 75.97\n",
      " acc: 0.8531 macro-f1: 0.5250\n",
      "85.31 52.5\n",
      " acc: 0.9211 macro-f1: 0.9245\n",
      "92.11 92.45\n",
      " acc: 0.9072 macro-f1: 0.9037\n",
      "90.72 90.37\n",
      " acc: 0.7688 macro-f1: 0.7555\n",
      "76.88 75.55\n",
      " acc: 0.8552 macro-f1: 0.5043\n",
      "85.52 50.43\n",
      " acc: 0.9263 macro-f1: 0.9292\n",
      "92.63 92.92\n",
      " acc: 0.9077 macro-f1: 0.9044\n",
      "90.77 90.44\n",
      " acc: 0.7698 macro-f1: 0.7580\n",
      "76.98 75.8\n",
      " acc: 0.8636 macro-f1: 0.5614\n",
      "86.36 56.14\n",
      " acc: 0.9386 macro-f1: 0.9396\n",
      "93.86 93.96\n",
      " acc: 0.8994 macro-f1: 0.8950\n",
      "89.94 89.5\n",
      " acc: 0.7483 macro-f1: 0.7432\n",
      "74.83 74.32\n",
      " acc: 0.8648 macro-f1: 0.5739\n",
      "86.48 57.39\n",
      " acc: 0.9396 macro-f1: 0.9406\n",
      "93.96 94.06\n",
      " acc: 0.8995 macro-f1: 0.8955\n",
      "89.95 89.55\n",
      " acc: 0.7500 macro-f1: 0.7472\n",
      "75 74.72\n",
      " acc: 0.7570 macro-f1: 0.5105\n",
      "75.7 51.05\n",
      " acc: 0.8402 macro-f1: 0.8403\n",
      "84.02 84.03\n",
      " acc: 0.7544 macro-f1: 0.7428\n",
      "75.44 74.28\n",
      " acc: 0.6952 macro-f1: 0.6626\n",
      "69.52 66.26\n",
      " acc: 0.7639 macro-f1: 0.5391\n",
      "76.39 53.91\n",
      " acc: 0.9262 macro-f1: 0.9261\n",
      "92.62 92.61\n",
      " acc: 0.8260 macro-f1: 0.8227\n",
      "82.6 82.27\n",
      " acc: 0.7121 macro-f1: 0.6883\n",
      "71.21 68.83\n",
      " acc: 0.7594 macro-f1: 0.5081\n",
      "75.94 50.81\n",
      " acc: 0.8487 macro-f1: 0.8495\n",
      "84.87 84.95\n",
      " acc: 0.7647 macro-f1: 0.7530\n",
      "76.47 75.3\n",
      " acc: 0.7240 macro-f1: 0.6807\n",
      "72.4 68.07\n",
      " acc: 0.7654 macro-f1: 0.5661\n",
      "76.54 56.61\n",
      " acc: 0.9260 macro-f1: 0.9277\n",
      "92.6 92.77\n",
      " acc: 0.8360 macro-f1: 0.8334\n",
      "83.6 83.34\n",
      " acc: 0.7368 macro-f1: 0.7019\n",
      "73.68 70.19\n",
      " acc: 0.7488 macro-f1: 0.4938\n",
      "74.88 49.38\n",
      " acc: 0.9261 macro-f1: 0.9281\n",
      "92.61 92.81\n",
      " acc: 0.8960 macro-f1: 0.8930\n",
      "89.6 89.3\n",
      " acc: 0.7713 macro-f1: 0.7482\n",
      "77.13 74.82\n",
      " acc: 0.7530 macro-f1: 0.5438\n",
      "75.3 54.38\n",
      " acc: 0.9286 macro-f1: 0.9309\n",
      "92.86 93.09\n",
      " acc: 0.8995 macro-f1: 0.8965\n",
      "89.95 89.65\n",
      " acc: 0.7733 macro-f1: 0.7503\n",
      "77.33 75.03\n",
      " acc: 0.7597 macro-f1: 0.5516\n",
      "75.97 55.16\n",
      " acc: 0.9367 macro-f1: 0.9371\n",
      "93.67 93.71\n",
      " acc: 0.8890 macro-f1: 0.8854\n",
      "88.9 88.54\n",
      " acc: 0.7446 macro-f1: 0.7253\n",
      "74.46 72.53\n",
      " acc: 0.7599 macro-f1: 0.5215\n",
      "75.99 52.15\n",
      " acc: 0.9399 macro-f1: 0.9403\n",
      "93.99 94.03\n",
      " acc: 0.8903 macro-f1: 0.8867\n",
      "89.03 88.67\n",
      " acc: 0.7516 macro-f1: 0.7332\n",
      "75.16 73.32\n",
      " acc: 0.7743 macro-f1: 0.5495\n",
      "77.43 54.95\n",
      " acc: 0.9331 macro-f1: 0.9345\n",
      "93.31 93.45\n",
      " acc: 0.8965 macro-f1: 0.8929\n",
      "89.65 89.29\n",
      " acc: 0.7695 macro-f1: 0.7428\n",
      "76.95 74.28\n",
      " acc: 0.7748 macro-f1: 0.5530\n",
      "77.48 55.3\n",
      " acc: 0.9357 macro-f1: 0.9371\n",
      "93.57 93.71\n",
      " acc: 0.8983 macro-f1: 0.8946\n",
      "89.83 89.46\n",
      " acc: 0.7727 macro-f1: 0.7468\n",
      "77.27 74.68\n",
      " acc: 0.7824 macro-f1: 0.5399\n",
      "78.24 53.99\n",
      " acc: 0.9261 macro-f1: 0.9281\n",
      "92.61 92.81\n",
      " acc: 0.8960 macro-f1: 0.8930\n",
      "89.6 89.3\n",
      " acc: 0.7713 macro-f1: 0.7482\n",
      "77.13 74.82\n",
      " acc: 0.7833 macro-f1: 0.5470\n",
      "78.33 54.7\n",
      " acc: 0.9286 macro-f1: 0.9309\n",
      "92.86 93.09\n",
      " acc: 0.8995 macro-f1: 0.8965\n",
      "89.95 89.65\n",
      " acc: 0.7733 macro-f1: 0.7503\n",
      "77.33 75.03\n",
      " acc: 0.7630 macro-f1: 0.5648\n",
      "76.3 56.48\n",
      " acc: 0.9403 macro-f1: 0.9406\n",
      "94.03 94.06\n",
      " acc: 0.8892 macro-f1: 0.8853\n",
      "88.92 88.53\n",
      " acc: 0.7444 macro-f1: 0.7262\n",
      "74.44 72.62\n",
      " acc: 0.7633 macro-f1: 0.5356\n",
      "76.33 53.56\n",
      " acc: 0.9436 macro-f1: 0.9440\n",
      "94.36 94.4\n",
      " acc: 0.8906 macro-f1: 0.8867\n",
      "89.06 88.67\n",
      " acc: 0.7509 macro-f1: 0.7328\n",
      "75.09 73.28\n",
      " acc: 0.6587 macro-f1: 0.5018\n",
      "65.87 50.18\n",
      " acc: 0.7448 macro-f1: 0.7519\n",
      "74.48 75.19\n",
      " acc: 0.8557 macro-f1: 0.8508\n",
      "85.57 85.08\n",
      " acc: 0.7171 macro-f1: 0.7068\n",
      "71.71 70.68\n",
      " acc: 0.6628 macro-f1: 0.5225\n",
      "66.28 52.25\n",
      " acc: 0.7992 macro-f1: 0.8066\n",
      "79.92 80.66\n",
      " acc: 0.8622 macro-f1: 0.8577\n",
      "86.22 85.77\n",
      " acc: 0.7288 macro-f1: 0.7193\n",
      "72.88 71.93\n",
      " acc: 0.5753 macro-f1: 0.4054\n",
      "57.53 40.54\n",
      " acc: 0.6800 macro-f1: 0.7030\n",
      "68 70.3\n",
      " acc: 0.8612 macro-f1: 0.8577\n",
      "86.12 85.77\n",
      " acc: 0.7343 macro-f1: 0.7200\n",
      "73.43 72\n",
      " acc: 0.5780 macro-f1: 0.4391\n",
      "57.8 43.91\n",
      " acc: 0.7262 macro-f1: 0.7484\n",
      "72.62 74.84\n",
      " acc: 0.8664 macro-f1: 0.8634\n",
      "86.64 86.34\n",
      " acc: 0.7440 macro-f1: 0.7348\n",
      "74.4 73.48\n",
      " acc: 0.4558 macro-f1: 0.3538\n",
      "45.58 35.38\n",
      " acc: 0.6154 macro-f1: 0.6413\n",
      "61.54 64.13\n",
      " acc: 0.8395 macro-f1: 0.8357\n",
      "83.95 83.57\n",
      " acc: 0.7217 macro-f1: 0.6987\n",
      "72.17 69.87\n",
      " acc: 0.4567 macro-f1: 0.3366\n",
      "45.67 33.66\n",
      " acc: 0.6647 macro-f1: 0.6929\n",
      "66.47 69.29\n",
      " acc: 0.8482 macro-f1: 0.8455\n",
      "84.82 84.55\n",
      " acc: 0.7349 macro-f1: 0.7212\n",
      "73.49 72.12\n",
      " acc: 0.7319 macro-f1: 0.4701\n",
      "73.19 47.01\n",
      " acc: 0.7803 macro-f1: 0.7898\n",
      "78.03 78.98\n",
      " acc: 0.8543 macro-f1: 0.8491\n",
      "85.43 84.91\n",
      " acc: 0.7020 macro-f1: 0.6803\n",
      "70.2 68.03\n",
      " acc: 0.7376 macro-f1: 0.5263\n",
      "73.76 52.63\n",
      " acc: 0.8323 macro-f1: 0.8382\n",
      "83.23 83.82\n",
      " acc: 0.8628 macro-f1: 0.8589\n",
      "86.28 85.89\n",
      " acc: 0.7242 macro-f1: 0.7151\n",
      "72.42 71.51\n",
      " acc: 0.6557 macro-f1: 0.4429\n",
      "65.57 44.29\n",
      " acc: 0.7070 macro-f1: 0.7268\n",
      "70.7 72.68\n",
      " acc: 0.8556 macro-f1: 0.8511\n",
      "85.56 85.11\n",
      " acc: 0.6970 macro-f1: 0.6581\n",
      "69.7 65.81\n",
      " acc: 0.6588 macro-f1: 0.4559\n",
      "65.88 45.59\n",
      " acc: 0.7611 macro-f1: 0.7782\n",
      "76.11 77.82\n",
      " acc: 0.8674 macro-f1: 0.8645\n",
      "86.74 86.45\n",
      " acc: 0.7267 macro-f1: 0.7089\n",
      "72.67 70.89\n",
      " acc: 0.5360 macro-f1: 0.3678\n",
      "53.6 36.78\n",
      " acc: 0.6556 macro-f1: 0.6809\n",
      "65.56 68.09\n",
      " acc: 0.7984 macro-f1: 0.7913\n",
      "79.84 79.13\n",
      " acc: 0.6334 macro-f1: 0.5817\n",
      "63.34 58.17\n",
      " acc: 0.5408 macro-f1: 0.3680\n",
      "54.08 36.8\n",
      " acc: 0.7108 macro-f1: 0.7367\n",
      "71.08 73.67\n",
      " acc: 0.8449 macro-f1: 0.8427\n",
      "84.49 84.27\n",
      " acc: 0.7043 macro-f1: 0.6752\n",
      "70.43 67.52\n",
      " acc: 0.7261 macro-f1: 0.4958\n",
      "72.61 49.58\n",
      " acc: 0.7746 macro-f1: 0.7831\n",
      "77.46 78.31\n",
      " acc: 0.8555 macro-f1: 0.8502\n",
      "85.55 85.02\n",
      " acc: 0.6979 macro-f1: 0.6708\n",
      "69.79 67.08\n",
      " acc: 0.7321 macro-f1: 0.5222\n",
      "73.21 52.22\n",
      " acc: 0.8206 macro-f1: 0.8262\n",
      "82.06 82.62\n",
      " acc: 0.8639 macro-f1: 0.8599\n",
      "86.39 85.99\n",
      " acc: 0.7228 macro-f1: 0.7091\n",
      "72.28 70.91\n"
     ]
    }
   ],
   "source": [
    "df = []\n",
    "for model in models:\n",
    "    quantizations = models[model]\n",
    "    for quant in quantizations:\n",
    "        for cleaner in cleaners:\n",
    "            results_path = f\"{ROOT_DIR}/{MODEL_TO_NAME[model]}/{quant}/{cleaner}\"\n",
    "            if os.path.exists(results_path):\n",
    "                results_entry = {\n",
    "                    'model': model,\n",
    "                    'quantization': quant,\n",
    "                    'cleaner': cleaner\n",
    "                }\n",
    "\n",
    "                for task in tasks:\n",
    "                    results = None\n",
    "                    data_path = f\"{results_path}/{task}-{model}.json\"\n",
    "                    if os.path.exists(data_path):\n",
    "                        results = json.load(open(data_path))\n",
    "                    else:\n",
    "                        data_path = f\"{results_path}/{task}-{model}.jsonl\"\n",
    "                        if os.path.exists(data_path):\n",
    "                            results = open(data_path).read().splitlines()\n",
    "                            results = [json.loads(entry) for entry in results]\n",
    "                    \n",
    "                    if results is not None:\n",
    "                        intents = open(f\"{DATA_DIR}/{task}/intents.txt\").read().splitlines()\n",
    "                        labels = []\n",
    "                        preds = []\n",
    "                        for entry in results:\n",
    "                            label = intents.index(entry['label'])\n",
    "                            labels.append(label)\n",
    "                            if cleaner == 'raw':\n",
    "                                model_out = entry['model_out'].strip()\n",
    "                                model_out = model_out.split(' ')[-1]\n",
    "                                if model_out in intents:\n",
    "                                    preds.append(intents.index(model_out))\n",
    "                                else:\n",
    "                                    preds.append((label + 1) % len(intents))\n",
    "                            elif cleaner == 'lmclean2':\n",
    "                                if entry['cleaned'] in intents:\n",
    "                                    preds.append(intents.index(entry['cleaned']))\n",
    "                                else:\n",
    "                                    preds.append(intents.index(map_to_intent(entry['cleaned'], intents)))\n",
    "                        labels = np.array(labels)\n",
    "                        preds = np.array(preds)\n",
    "                        acc, f1 = score(labels, preds)\n",
    "                        results_entry[f\"{task}-acc\"] = acc\n",
    "                        results_entry[f\"{task}-f1\"] = f1\n",
    "                df.append(results_entry)\n",
    "df = pd.DataFrame(df)\n",
    "df.to_excel('post_processing_effects.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c6d673",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
